# Model configuration
model:
  model_id: "meta-llama/Llama-3.2-3B-Instruct"
  target_model_id: "meta-llama/Llama-3.2-3B-Instruct"
  pretrained_id: "Condense-AI/Condenser-Llama-3.2-3B-Instruct-20241229-192753"
  num_condense_tokens: 128
  max_length: 4096
  lora_r: 512
  lora_alpha: 512
  lora_dropout: 0.0
  compress_rate: 4

# Dataset configuration
dataset:
  dataset_id: "DKYoon/SlimPajama-6B"
  train_split: 0.9
  min_text_length: 5000

# Training configuration
training:
  batch_size: 1
  num_workers: 8
  devices: -1
  max_epochs: 10
  precision: "bf16-true"
  gradient_clip_val: 1.0
  log_every_n_steps: 5
  check_val_every_n_epoch: 1
  val_check_interval: 500
  limit_val_batches: 100

# Logging configuration
logging:
  wandb_project: "Condense" 